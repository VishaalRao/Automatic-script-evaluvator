{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Script Evaluvator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook by __[Vishaal Rao](https://www.linkedin.com/in/vishaal-rao/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    " 1. [Introduction](#Introduction)\n",
    " 2. [Libraries used](#Important-Libraries-used-in-the-following-project)\n",
    " 3. [Problem Domain](#The-Problem-Domain)\n",
    " 4. [Methodology](#Methodology)\n",
    " 5. [Program](#Program)\n",
    " 6. [N/A value treatment](#N/A-value-treatment)\n",
    " 7. [Performing Natural language process](#Performing-Natural-language-process)\n",
    " 8. [Building Regression model](#Building-Regression-model)\n",
    " 9. [Predicting the scores for the given test data](#Predicting-the-scores-for-the-given-test-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The number of students around the globe enrolled in higher education is forecast to more than double to 262 million by 2025. Nearly all of this growth will be in the developing world, with more than half in China and India alone. With every student giving exams to prove themselves to be cut above the rest, It leaves the teachers around the world with the daunting task of correcting every single paper a student submits.\n",
    "\n",
    "In this notebook i'll be attempting to grade 10 different sets of essays answered by students, which has been marked according to the coherence and clarity by 2 different teachers. While the teacher have given 5 seperate scores with a maximum marks of either 2 or 3(depending on the set), i'll be taking the mean of these marks and will be assigning total marks out of 10 or 15 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Libraries used in the following project\n",
    "\n",
    "1. **NLTK**: The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing for English written in the Python programming language.\n",
    "\n",
    "\n",
    "2. **Pandas** :pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "\n",
    "\n",
    "3. **sklearn.feature_extraction.text** The library has been used to perform TFIDF vectorization.\n",
    "\n",
    "\n",
    "4. **sklearn.metrics.pairwise** : The library has been used to obtain the cosine similarity for the essay text.\n",
    "\n",
    "\n",
    "5. **sklearn.ensemble** : The library has been used to perform bagging for the model.\n",
    "\n",
    "\n",
    "6. **sklearn.tree** : Descision tree regressor has been called from the library mentioned.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem Domain \n",
    "For the purpose of this exercise, let's pretend a school has asked us to buid a machine learning algorithm which shall automatically grade the essay's submitted by students of grade 10. We have been given 4 inputs namely Essay set, coherence, clarity and the essay text written by th student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "\n",
    "\n",
    "1. In order to judge the essays based on text we will be comparing all the essays having the highest clarity and coherence in their sets. We will be comparing it using:\n",
    "    \n",
    "    1. **Term frequency**: is a scoring of the frequency of the word in the current document.\n",
    "                    \n",
    "          *TF = (Number of times term t appears in a document)/(Number of terms in the document)*\n",
    "    \n",
    "    2. **Inverse Document frequency**:  is a scoring of how rare the word is across documents.\n",
    "    \n",
    "          *IDF = 1+log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in.*\n",
    "        \n",
    "Tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus\n",
    "\n",
    "\n",
    "\n",
    "2. **Cosine Similarity** :Cosine similarity is a measure of similarity between two non-zero vectors. Using this formula we can find out the similarity between any two documents d1 and d2.\n",
    "\n",
    "      *Cosine Similarity (d1, d2) =  Dot product(d1, d2) / ||d1|| * ||d2||*\n",
    "      \n",
    "      where d1,d2 are two non zero vectors. In our scenario, d1 will be one of the essay texts we are testing and d2 will be one of the essay text which has been rate highly.The similarity shall be stored in a column named 'EssayMrk\n",
    "      \n",
    "\n",
    "\n",
    "3. **Decision Tree Regressor**: We shall be using a descision tree regressor where the 'Essayset','clarity','coherent','EssayMrk' shall be the independent variable and the 'Total' shall be the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4. **Bagging Regressor**: We shall be using the ensamble Bagging to improve the accuracy of the said model.\n",
    "\n",
    "      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vishaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:\\Data science\\Kaggle project\\incedo_participant')\n",
    "\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=pd.read_csv('train_dataset.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17043, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>worst</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>worst</td>\n",
       "      <td>above_average</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>above_average</td>\n",
       "      <td>worst</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Essayset  min_score  max_score  score_1  score_2  score_3  score_4  \\\n",
       "0   1       1.0          0          3        1        1      1.0      1.0   \n",
       "1   2       1.0          0          3        1        1      NaN      1.5   \n",
       "2   3       1.0          0          3        1        1      1.0      1.0   \n",
       "3   4       1.0          0          3        0        0      0.0      0.0   \n",
       "4   5       1.0          0          3        2        2      2.0      2.5   \n",
       "\n",
       "   score_5        clarity       coherent  \\\n",
       "0      1.0        average          worst   \n",
       "1      1.0      excellent          worst   \n",
       "2      1.5          worst  above_average   \n",
       "3      1.0          worst          worst   \n",
       "4      1.0  above_average          worst   \n",
       "\n",
       "                                           EssayText  \n",
       "0  Some additional information that we would need...  \n",
       "1  After reading the expirement, I realized that ...  \n",
       "2  What you need is more trials, a control set up...  \n",
       "3  The student should list what rock is better an...  \n",
       "4  For the students to be able to make a replicat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             int64\n",
       "Essayset     float64\n",
       "min_score      int64\n",
       "max_score      int64\n",
       "score_1        int64\n",
       "score_2        int64\n",
       "score_3      float64\n",
       "score_4      float64\n",
       "score_5      float64\n",
       "clarity       object\n",
       "coherent      object\n",
       "EssayText     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             0\n",
       "Essayset     157\n",
       "min_score      0\n",
       "max_score      0\n",
       "score_1        0\n",
       "score_2        0\n",
       "score_3      147\n",
       "score_4      136\n",
       "score_5      144\n",
       "clarity      138\n",
       "coherent     145\n",
       "EssayText      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N/A value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.dropna(subset=['Essayset'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['score_1']=Train['score_1'].fillna(round(Train['score_1'].mean()),axis=0)\n",
    "Train['score_2']=Train['score_2'].fillna(round(Train['score_2'].mean()),axis=0)\n",
    "Train['score_3']=Train['score_3'].fillna(round(Train['score_3'].mean()),axis=0)\n",
    "Train['score_4']=Train['score_4'].fillna(round(Train['score_4'].mean()),axis=0)\n",
    "Train['score_5']=Train['score_5'].fillna(round(Train['score_5'].mean()),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['clarity'] = Train['clarity'].map( {'worst':0, 'average':1, 'above_average':2,'excellent':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['coherent'] = Train['coherent'].map( {'worst':0, 'average':1, 'above_average':2,'excellent':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['clarity']=Train['clarity'].fillna(round(Train['clarity'].mean()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['coherent']=Train['coherent'].fillna(round(Train['coherent'].mean()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Essayset     0\n",
       "min_score    0\n",
       "max_score    0\n",
       "score_1      0\n",
       "score_2      0\n",
       "score_3      0\n",
       "score_4      0\n",
       "score_5      0\n",
       "clarity      0\n",
       "coherent     0\n",
       "EssayText    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Essayset  min_score  max_score  score_1  score_2  score_3  score_4  \\\n",
       "0   1       1.0          0          3        1        1      1.0      1.0   \n",
       "1   2       1.0          0          3        1        1      1.0      1.5   \n",
       "2   3       1.0          0          3        1        1      1.0      1.0   \n",
       "3   4       1.0          0          3        0        0      0.0      0.0   \n",
       "4   5       1.0          0          3        2        2      2.0      2.5   \n",
       "\n",
       "   score_5  clarity  coherent  \\\n",
       "0      1.0      1.0       0.0   \n",
       "1      1.0      3.0       0.0   \n",
       "2      1.5      0.0       2.0   \n",
       "3      1.0      0.0       0.0   \n",
       "4      1.0      2.0       0.0   \n",
       "\n",
       "                                           EssayText  \n",
       "0  Some additional information that we would need...  \n",
       "1  After reading the expirement, I realized that ...  \n",
       "2  What you need is more trials, a control set up...  \n",
       "3  The student should list what rock is better an...  \n",
       "4  For the students to be able to make a replicat...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the mean of all the score and dividing by the maxium score that can be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['Total']=round((Train['score_1']+Train['score_2']+Train['score_3']+Train['score_4']+Train['score_5'])/(Train['max_score']*5),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Essayset  min_score  max_score  score_1  score_2  score_3  score_4  \\\n",
       "0   1       1.0          0          3        1        1      1.0      1.0   \n",
       "1   2       1.0          0          3        1        1      1.0      1.5   \n",
       "2   3       1.0          0          3        1        1      1.0      1.0   \n",
       "3   4       1.0          0          3        0        0      0.0      0.0   \n",
       "4   5       1.0          0          3        2        2      2.0      2.5   \n",
       "\n",
       "   score_5  clarity  coherent  \\\n",
       "0      1.0      1.0       0.0   \n",
       "1      1.0      3.0       0.0   \n",
       "2      1.5      0.0       2.0   \n",
       "3      1.0      0.0       0.0   \n",
       "4      1.0      2.0       0.0   \n",
       "\n",
       "                                           EssayText  Total  \n",
       "0  Some additional information that we would need...   0.33  \n",
       "1  After reading the expirement, I realized that ...   0.37  \n",
       "2  What you need is more trials, a control set up...   0.37  \n",
       "3  The student should list what rock is better an...   0.07  \n",
       "4  For the students to be able to make a replicat...   0.63  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.drop(['ID','min_score','max_score','score_1','score_2','score_3','score_4','score_5'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essayset</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essayset  clarity  coherent  \\\n",
       "0       1.0      1.0       0.0   \n",
       "1       1.0      3.0       0.0   \n",
       "2       1.0      0.0       2.0   \n",
       "3       1.0      0.0       0.0   \n",
       "4       1.0      2.0       0.0   \n",
       "\n",
       "                                           EssayText  Total  \n",
       "0  Some additional information that we would need...   0.33  \n",
       "1  After reading the expirement, I realized that ...   0.37  \n",
       "2  What you need is more trials, a control set up...   0.37  \n",
       "3  The student should list what rock is better an...   0.07  \n",
       "4  For the students to be able to make a replicat...   0.63  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Train['EssayText'])):\n",
    "    Train.iloc[i,3]=Train.iloc[i,3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essayset</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>some additional information that we would need...</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>after reading the expirement, i realized that ...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>what you need is more trials, a control set up...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the student should list what rock is better an...</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>for the students to be able to make a replicat...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essayset  clarity  coherent  \\\n",
       "0       1.0      1.0       0.0   \n",
       "1       1.0      3.0       0.0   \n",
       "2       1.0      0.0       2.0   \n",
       "3       1.0      0.0       0.0   \n",
       "4       1.0      2.0       0.0   \n",
       "\n",
       "                                           EssayText  Total  \n",
       "0  some additional information that we would need...   0.33  \n",
       "1  after reading the expirement, i realized that ...   0.37  \n",
       "2  what you need is more trials, a control set up...   0.37  \n",
       "3  the student should list what rock is better an...   0.07  \n",
       "4  for the students to be able to make a replicat...   0.63  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Natural language process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the rows based on the 'Essayset' they belong to. In this problem there are 10 different essay sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train['Essayset'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tab_1=[]\n",
    "Tab_2=[]\n",
    "Tab_3=[]\n",
    "Tab_4=[]\n",
    "Tab_5=[]\n",
    "Tab_6=[]\n",
    "Tab_7=[]\n",
    "Tab_8=[]\n",
    "Tab_9=[]\n",
    "Tab_10=[]\n",
    "for j in range(0,len(Train['Essayset'])):\n",
    "        if Train.iloc[j,0]==1:\n",
    "            Tab_1.insert(len(Tab_1),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==2:\n",
    "            Tab_2.insert(len(Tab_2),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==3:\n",
    "            Tab_3.insert(len(Tab_3),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==4:\n",
    "            Tab_4.insert(len(Tab_4),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==5:\n",
    "            Tab_5.insert(len(Tab_5),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==6:\n",
    "            Tab_6.insert(len(Tab_6),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==7:\n",
    "            Tab_7.insert(len(Tab_7),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==8:\n",
    "            Tab_8.insert(len(Tab_8),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==9:\n",
    "            Tab_9.insert(len(Tab_9),Train.iloc[j,:])\n",
    "        elif Train.iloc[j,0]==10:\n",
    "            Tab_10.insert(len(Tab_10),Train.iloc[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tab_1=pd.DataFrame(Tab_1)\n",
    "Tab_2=pd.DataFrame(Tab_2)\n",
    "Tab_3=pd.DataFrame(Tab_3)\n",
    "Tab_4=pd.DataFrame(Tab_4)\n",
    "Tab_5=pd.DataFrame(Tab_5)\n",
    "Tab_6=pd.DataFrame(Tab_6)\n",
    "Tab_7=pd.DataFrame(Tab_7)\n",
    "Tab_8=pd.DataFrame(Tab_8)\n",
    "Tab_9=pd.DataFrame(Tab_9)\n",
    "Tab_10=pd.DataFrame(Tab_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tab_1.reset_index(inplace=True,drop=True)\n",
    "Tab_2.reset_index(inplace=True,drop=True)\n",
    "Tab_3.reset_index(inplace=True,drop=True)\n",
    "Tab_4.reset_index(inplace=True,drop=True)\n",
    "Tab_5.reset_index(inplace=True,drop=True)\n",
    "Tab_6.reset_index(inplace=True,drop=True)\n",
    "Tab_7.reset_index(inplace=True,drop=True)\n",
    "Tab_8.reset_index(inplace=True,drop=True)\n",
    "Tab_9.reset_index(inplace=True,drop=True)\n",
    "Tab_10.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function **Best_vals** which shall return a list of the best rows with high 'coherence' and 'clarity'. It was noticed that essay set 6 did not have any good performers hence we have considered the rows with either high coherence or high clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Best_vals(df):\n",
    "    B_V=[]\n",
    "    for j in range(len(df)):\n",
    "        if j!=6:\n",
    "            if (df.iloc[j,1]==3) & (df.iloc[j,2]==3) :\n",
    "                B_V.append(j)\n",
    "        else:\n",
    "            if (df.iloc[j,1]==max(df.iloc[:,1])) | (df.iloc[j,2]==max(df.iloc[:,2])) :\n",
    "                B_V.append(j)\n",
    "    return B_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BV1=Best_vals(Tab_1)\n",
    "BV2=Best_vals(Tab_2)\n",
    "BV3=Best_vals(Tab_3)\n",
    "BV4=Best_vals(Tab_4)\n",
    "BV5=Best_vals(Tab_5)\n",
    "BV6=Best_vals(Tab_6)\n",
    "BV7=Best_vals(Tab_7)\n",
    "BV8=Best_vals(Tab_8)\n",
    "BV9=Best_vals(Tab_9)\n",
    "BV10=Best_vals(Tab_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions to perform **Lemmatization**. Lemmatization means returning the base form of a particular word. Examples of Lemmatization are that “run” is a base form for words like “running” or “ran” or that the word “better” and “good” are in the same lemma so they are considered the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function **Vals** returns the cosine similarity values of the essay texts. it shall be done seperately for seperate essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vals(Tab,BV):\n",
    "    vals=[]\n",
    "    Tab_list=list(Tab)\n",
    "    z=np.zeros((1,len(Tab_list)))\n",
    "    vectorizer = TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
    "    X = vectorizer.fit_transform(Tab_list)            #Input Tab will have to be a list, so input Tab_1.iloc[:,0]\n",
    "    for i,v in enumerate(BV):    \n",
    "        vals=cosine_similarity(X[v], X)\n",
    "        z=np.append(z,vals,axis=0)\n",
    "    z=np.delete(z, 0, 0)\n",
    "    Mean=pd.DataFrame(z.mean(axis=0))\n",
    "    \n",
    "    return Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EssayMark1=Vals(Tab_1.iloc[:,3],BV1)\n",
    "EssayMark2=Vals(Tab_2.iloc[:,3],BV2)\n",
    "EssayMark3=Vals(Tab_3.iloc[:,3],BV3)\n",
    "EssayMark4=Vals(Tab_4.iloc[:,3],BV4)\n",
    "EssayMark5=Vals(Tab_5.iloc[:,3],BV5)\n",
    "EssayMark6=Vals(Tab_6.iloc[:,3],BV6)\n",
    "EssayMark7=Vals(Tab_7.iloc[:,3],BV7)\n",
    "EssayMark8=Vals(Tab_8.iloc[:,3],BV8)\n",
    "EssayMark9=Vals(Tab_9.iloc[:,3],BV9)\n",
    "EssayMark10=Vals(Tab_10.iloc[:,3],BV10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[EssayMark1,EssayMark2,EssayMark3,EssayMark4,EssayMark5,EssayMark6,EssayMark7,EssayMark8,EssayMark9,EssayMark10]\n",
    "EssayMark=[]\n",
    "for i in range(len(lst)):\n",
    "    EssayMark.extend(lst[i].iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EssayMark=pd.DataFrame(EssayMark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EssayMark.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['EssayMrk']=EssayMark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Essayset     0\n",
       "clarity      0\n",
       "coherent     0\n",
       "EssayText    0\n",
       "Total        0\n",
       "EssayMrk     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essayset</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>Total</th>\n",
       "      <th>EssayMrk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.145242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.046966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.042876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.015729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.075880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essayset  clarity  coherent  Total  EssayMrk\n",
       "0       1.0      1.0       0.0   0.33  0.145242\n",
       "1       1.0      3.0       0.0   0.37  0.046966\n",
       "2       1.0      0.0       2.0   0.37  0.042876\n",
       "3       1.0      0.0       0.0   0.07  0.015729\n",
       "4       1.0      2.0       0.0   0.63  0.075880"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.drop('EssayText',inplace=True,axis=1)\n",
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essayset</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>Total</th>\n",
       "      <th>EssayMrk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.145242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.046966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.042876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.015729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.075880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essayset  clarity  coherent  Total  EssayMrk\n",
       "0       1.0      1.0       0.0   0.33  0.145242\n",
       "1       1.0      3.0       0.0   0.37  0.046966\n",
       "2       1.0      0.0       2.0   0.37  0.042876\n",
       "3       1.0      0.0       0.0   0.07  0.015729\n",
       "4       1.0      2.0       0.0   0.63  0.075880"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head() # Final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Essayset    0\n",
       "clarity     0\n",
       "coherent    0\n",
       "Total       0\n",
       "EssayMrk    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = BaggingRegressor(base_estimator=DecisionTreeRegressor(),oob_score=True)\n",
    "X=Train[['Essayset','clarity','coherent','EssayMrk']]\n",
    "Y=Train[['Total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=True,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  0.6546685882580758\n"
     ]
    }
   ],
   "source": [
    "print ('Coefficients: ', regr.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7078440593172011"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform Bagging on multiple estimatiors in order to achieve the most efficient model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators = 10\n",
      "OOB score is 0.6636541351563024\n",
      "************************\n",
      "For n_estimators = 30\n",
      "OOB score is 0.717162318458297\n",
      "************************\n",
      "For n_estimators = 50\n",
      "OOB score is 0.7235625779116421\n",
      "************************\n",
      "For n_estimators = 70\n",
      "OOB score is 0.7254154129084711\n",
      "************************\n",
      "For n_estimators = 90\n",
      "OOB score is 0.7275251725391145\n",
      "************************\n",
      "For n_estimators = 110\n",
      "OOB score is 0.7278178050931972\n",
      "************************\n",
      "For n_estimators = 130\n",
      "OOB score is 0.7288367215486253\n",
      "************************\n",
      "For n_estimators = 150\n",
      "OOB score is 0.7294000969816308\n",
      "************************\n",
      "For n_estimators = 170\n",
      "OOB score is 0.7296874255154073\n",
      "************************\n",
      "For n_estimators = 190\n",
      "OOB score is 0.729781389465202\n",
      "************************\n",
      "For n_estimators = 210\n",
      "OOB score is 0.729901439260723\n",
      "************************\n",
      "For n_estimators = 230\n",
      "OOB score is 0.7298908254762734\n",
      "************************\n",
      "For n_estimators = 250\n",
      "OOB score is 0.729947178253558\n",
      "************************\n",
      "For n_estimators = 270\n",
      "OOB score is 0.7298747113503099\n",
      "************************\n",
      "For n_estimators = 290\n",
      "OOB score is 0.729804523206496\n",
      "************************\n"
     ]
    }
   ],
   "source": [
    "for w in range(10,300,20):\n",
    "    regr=BaggingRegressor(oob_score=True,n_jobs=-1,n_estimators=w,random_state=400,\n",
    "                          base_estimator=DecisionTreeRegressor())\n",
    "    regr.fit(X_train,y_train)\n",
    "    oob=regr.oob_score_\n",
    "    print('For n_estimators = '+str(w))\n",
    "    print('OOB score is '+str(oob))\n",
    "    print('************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=250, n_jobs=-1, oob_score=True,\n",
       "         random_state=400, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr=BaggingRegressor(oob_score=True,n_jobs=-1,n_estimators=250,random_state=400, #It was noticed that when estimator=250, the model had the highest efficiency.\n",
    "                          base_estimator=DecisionTreeRegressor())\n",
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall see the which split had the most affect in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=[]\n",
    "for i in regr.estimators_:\n",
    "    imp.append(i.feature_importances_)\n",
    "imp=np.mean(imp,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance=pd.Series(imp,index=X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coherent    0.506951\n",
       "EssayMrk    0.219869\n",
       "clarity     0.185002\n",
       "Essayset    0.088178\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was noticed that coherence has played the most important part in judging a students performance, followed by the cosine similarity to the best written essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7200323358633295"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above built model has an efficiency of **72%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the scores for the given test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>The procedures I think they should have includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>In order to replicate this experiment, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>above_average</td>\n",
       "      <td>above_average</td>\n",
       "      <td>In order to replicate their experiment, you wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Pleace a simple of one material into one conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Determin the mass of four different samples ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Essayset  min_score  max_score        clarity       coherent  \\\n",
       "0  1673         1          0          3        average          worst   \n",
       "1  1674         1          0          3        average          worst   \n",
       "2  1675         1          0          3  above_average  above_average   \n",
       "3  1676         1          0          3          worst          worst   \n",
       "4  1677         1          0          3          worst          worst   \n",
       "\n",
       "                                           EssayText  \n",
       "0  The procedures I think they should have includ...  \n",
       "1  In order to replicate this experiment, you wou...  \n",
       "2  In order to replicate their experiment, you wo...  \n",
       "3  Pleace a simple of one material into one conta...  \n",
       "4  Determin the mass of four different samples ma...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test['clarity'] = Test['clarity'].map( {'worst':0, 'average':1, 'above_average':2,'excellent':3})\n",
    "Test['coherent'] = Test['coherent'].map( {'worst':0, 'average':1, 'above_average':2,'excellent':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.drop(['ID','min_score'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Test['EssayText'])):\n",
    "    Test.iloc[i,4]=Test.iloc[i,4].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essayset</th>\n",
       "      <th>max_score</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the procedures i think they should have includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>in order to replicate this experiment, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>in order to replicate their experiment, you wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pleace a simple of one material into one conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>determin the mass of four different samples ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essayset  max_score  clarity  coherent  \\\n",
       "0         1          3        1         0   \n",
       "1         1          3        1         0   \n",
       "2         1          3        2         2   \n",
       "3         1          3        0         0   \n",
       "4         1          3        0         0   \n",
       "\n",
       "                                           EssayText  \n",
       "0  the procedures i think they should have includ...  \n",
       "1  in order to replicate this experiment, you wou...  \n",
       "2  in order to replicate their experiment, you wo...  \n",
       "3  pleace a simple of one material into one conta...  \n",
       "4  determin the mass of four different samples ma...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Tab_1=[]\n",
    "Test_Tab_2=[]\n",
    "Test_Tab_3=[]\n",
    "Test_Tab_4=[]\n",
    "Test_Tab_5=[]\n",
    "Test_Tab_6=[]\n",
    "Test_Tab_7=[]\n",
    "Test_Tab_8=[]\n",
    "Test_Tab_9=[]\n",
    "Test_Tab_10=[]\n",
    "for j in range(0,len(Test['Essayset'])):\n",
    "        if Test.iloc[j,0]==1:\n",
    "            Test_Tab_1.insert(len(Test_Tab_1),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==2:\n",
    "            Test_Tab_2.insert(len(Test_Tab_2),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==3:\n",
    "            Test_Tab_3.insert(len(Test_Tab_3),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==4:\n",
    "            Test_Tab_4.insert(len(Test_Tab_4),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==5:\n",
    "            Test_Tab_5.insert(len(Test_Tab_5),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==6:\n",
    "            Test_Tab_6.insert(len(Test_Tab_6),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==7:\n",
    "            Test_Tab_7.insert(len(Test_Tab_7),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==8:\n",
    "            Test_Tab_8.insert(len(Test_Tab_8),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==9:\n",
    "            Test_Tab_9.insert(len(Test_Tab_9),Test.iloc[j,:])\n",
    "        elif Test.iloc[j,0]==10:\n",
    "            Test_Tab_10.insert(len(Test_Tab_10),Test.iloc[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Tab_1=pd.DataFrame(Test_Tab_1)\n",
    "Test_Tab_2=pd.DataFrame(Test_Tab_2)\n",
    "Test_Tab_3=pd.DataFrame(Test_Tab_3)\n",
    "Test_Tab_4=pd.DataFrame(Test_Tab_4)\n",
    "Test_Tab_5=pd.DataFrame(Test_Tab_5)\n",
    "Test_Tab_6=pd.DataFrame(Test_Tab_6)\n",
    "Test_Tab_7=pd.DataFrame(Test_Tab_7)\n",
    "Test_Tab_8=pd.DataFrame(Test_Tab_8)\n",
    "Test_Tab_9=pd.DataFrame(Test_Tab_9)\n",
    "Test_Tab_10=pd.DataFrame(Test_Tab_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Tab_1.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_2.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_3.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_4.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_5.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_6.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_7.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_8.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_9.reset_index(inplace=True,drop=True)\n",
    "Test_Tab_10.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Best_vals2(df):\n",
    "    B_V=[]\n",
    "    for j in range(len(df)):\n",
    "        if (df.iloc[j,2]==max(df.iloc[:,2])) | (df.iloc[j,3]==max(df.iloc[:,3])) :\n",
    "            B_V.append(j)\n",
    "    return B_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_BV1=Best_vals2(Test_Tab_1)\n",
    "test_BV2=Best_vals2(Test_Tab_2)\n",
    "test_BV3=Best_vals2(Test_Tab_3)\n",
    "test_BV4=Best_vals2(Test_Tab_4)\n",
    "test_BV5=Best_vals2(Test_Tab_5)\n",
    "test_BV6=Best_vals2(Test_Tab_6)\n",
    "test_BV7=Best_vals2(Test_Tab_7)\n",
    "test_BV8=Best_vals2(Test_Tab_8)\n",
    "test_BV9=Best_vals2(Test_Tab_9)\n",
    "test_BV10=Best_vals2(Test_Tab_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_EssayMark1=Vals(Test_Tab_1.iloc[:,4],test_BV1)\n",
    "Test_EssayMark2=Vals(Test_Tab_2.iloc[:,4],test_BV2)\n",
    "Test_EssayMark3=Vals(Test_Tab_3.iloc[:,4],test_BV3)\n",
    "Test_EssayMark4=Vals(Test_Tab_4.iloc[:,4],test_BV4)\n",
    "Test_EssayMark5=Vals(Test_Tab_5.iloc[:,4],test_BV5)\n",
    "Test_EssayMark6=Vals(Test_Tab_6.iloc[:,4],test_BV6)\n",
    "Test_EssayMark7=Vals(Test_Tab_7.iloc[:,4],test_BV7)\n",
    "Test_EssayMark8=Vals(Test_Tab_8.iloc[:,4],test_BV8)\n",
    "Test_EssayMark9=Vals(Test_Tab_9.iloc[:,4],test_BV9)\n",
    "Test_EssayMark10=Vals(Test_Tab_10.iloc[:,4],test_BV10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst2=[Test_EssayMark1,Test_EssayMark2,Test_EssayMark3,Test_EssayMark4,Test_EssayMark5,Test_EssayMark6,Test_EssayMark7,Test_EssayMark8,Test_EssayMark9,Test_EssayMark10]\n",
    "Test_EssayMark=[]\n",
    "for i in range(len(lst2)):\n",
    "    Test_EssayMark.extend(lst2[i].iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "EssayMark2=pd.DataFrame(Test_EssayMark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test['EssayMrk']=EssayMark2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Essayset     0\n",
       "max_score    0\n",
       "clarity      0\n",
       "coherent     0\n",
       "EssayText    0\n",
       "EssayMrk     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essayset</th>\n",
       "      <th>max_score</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>EssayMrk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the procedures i think they should have includ...</td>\n",
       "      <td>0.077698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>in order to replicate this experiment, you wou...</td>\n",
       "      <td>0.135626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>in order to replicate their experiment, you wo...</td>\n",
       "      <td>0.114849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pleace a simple of one material into one conta...</td>\n",
       "      <td>0.051692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>determin the mass of four different samples ma...</td>\n",
       "      <td>0.047638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essayset  max_score  clarity  coherent  \\\n",
       "0         1          3        1         0   \n",
       "1         1          3        1         0   \n",
       "2         1          3        2         2   \n",
       "3         1          3        0         0   \n",
       "4         1          3        0         0   \n",
       "\n",
       "                                           EssayText  EssayMrk  \n",
       "0  the procedures i think they should have includ...  0.077698  \n",
       "1  in order to replicate this experiment, you wou...  0.135626  \n",
       "2  in order to replicate their experiment, you wo...  0.114849  \n",
       "3  pleace a simple of one material into one conta...  0.051692  \n",
       "4  determin the mass of four different samples ma...  0.047638  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat= regr.predict(Test[['Essayset','clarity','coherent','EssayMrk']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission=pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>The procedures I think they should have includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>In order to replicate this experiment, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>above_average</td>\n",
       "      <td>above_average</td>\n",
       "      <td>In order to replicate their experiment, you wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Pleace a simple of one material into one conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Determin the mass of four different samples ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Essayset  min_score  max_score        clarity       coherent  \\\n",
       "0  1673         1          0          3        average          worst   \n",
       "1  1674         1          0          3        average          worst   \n",
       "2  1675         1          0          3  above_average  above_average   \n",
       "3  1676         1          0          3          worst          worst   \n",
       "4  1677         1          0          3          worst          worst   \n",
       "\n",
       "                                           EssayText  \n",
       "0  The procedures I think they should have includ...  \n",
       "1  In order to replicate this experiment, you wou...  \n",
       "2  In order to replicate their experiment, you wo...  \n",
       "3  Pleace a simple of one material into one conta...  \n",
       "4  Determin the mass of four different samples ma...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission=Submission[['ID','Essayset','max_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission['Score']=round(y_hat*Submission['max_score']*5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission.drop('max_score',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1678</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1679</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1680</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1681</td>\n",
       "      <td>1</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1682</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Essayset  Score\n",
       "0  1673         1    1.6\n",
       "1  1674         1    4.3\n",
       "2  1675         1   12.4\n",
       "3  1676         1    3.0\n",
       "4  1677         1    3.3\n",
       "5  1678         1   11.0\n",
       "6  1679         1    2.4\n",
       "7  1680         1    3.4\n",
       "8  1681         1   13.6\n",
       "9  1682         1   10.5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission.to_csv('Submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
